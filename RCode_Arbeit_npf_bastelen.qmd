---
title: "R-Code Projektarbeit Pattre"
format: html
---

#Packages laden evtl. müssen gewisse noch installiert werden

```{r}
# Load necessary libraries
library(sf)
library(jsonlite)
library(dplyr)
library(tmap)
library(purrr)
library(ggplot2)
library(lubridate)
library(leaflet)
library(tmap)
library(ggmap)
library(ggspatial)
library(prettymapr)
library(osmdata)
# install.packages("osmdata")

```

#Daten einlesen

```{r}
# Load and process your data
#Serafin
records_json_S <- jsonlite::read_json("C:/Users/nadja/OneDrive - ZHAW/General/Projektarbeit/Ausgangsdaten/Serafin/Takeout_Serafin/Standortverlauf (Zeitachse)/Records.json", simplifyVector = TRUE)
records_S <- records_json_S[[1]] |> 
  mutate( Person = "Serafin")


#Nadja
records_json_N <- jsonlite::read_json("C:/Users/nadja/OneDrive - ZHAW/General/Projektarbeit/Ausgangsdaten/Nadja/Takeout/Standortverlauf (Zeitachse)/Records.json", simplifyVector = TRUE)
records_N <- records_json_N[[1]] |> 
  mutate( Person = "Nadja")


# zusammenführen
records <- bind_rows(records_N, records_S)




# Convert the data to an sf object and prepare coordinates
records_sf_both <- records %>%
  mutate(
    lat = latitudeE7 / 1e7,
    lon = longitudeE7 / 1e7,
    lat_copy = latitudeE7 / 1e7,  # Kopie der Latitude
    lon_copy = longitudeE7 / 1e7,  # Kopie der Longitude
    timestamp = as.POSIXct(timestamp, origin = "1970-01-01", tz = "UTC"),
    activity = map_chr(activity, ~ .x[[1]]$type %||% "UNKNOWN") # Assuming there is always at least one activity type; otherwise, it defaults to "UNKNOWN"  
  ) %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326)





names(records_sf_both)
```

#Daten filtern

```{r}
str(records_sf_both)

# Filtern nach dem Jahr 2024
records_sf <- records_sf_both %>%
  filter(year(timestamp) == 2024) 


```

#Plot Activity an einzelnem Tag

```{r}
# Filter Date
records_filtered <- records_sf_both %>%
  filter(as.Date(timestamp) == as.Date("2024-04-08"))

# Transform point data to a line representation
records_lines <- records_filtered %>%
  arrange(timestamp) %>%
  summarise(geometry = st_combine(geometry), activity = first(activity), .groups = "drop") %>%
  st_cast("LINESTRING")  # Cast MULTIPOINT to LINESTRING

# Define a color palette for activity types
activity_colors <- c("ON_FOOT" = "green", "TILTING" = "orange", "UNKNOWN" = "grey", "STILL" = "blue", "IN_VEHICLE" = "red")

# Visualize the point and line data on the map
# tmap <- 
  tm_shape(records_filtered) +
  tm_dots(size = 0.5, col = "black") +
  tm_shape(records_lines) +
  tm_lines(col = "activity", palette = activity_colors, title.col = "Activity Type") +
  tm_basemap(server = "OpenStreetMap") +
  tm_layout(main.title = "Visualisierung der geographischen Datenpunkte mit Aktivitätsniveau",
            main.title.position = "center") 

# Print the map
# print(tmap)
```

#Geschwindigkeit über Zeit mit Pausen \>\> es müssen noch auf Tage oder Zeitperiode definiert werden

```{r}

library(ggplot2)
library(dplyr)



# Hinzufügen einer simulierten Geschwindigkeit für das Beispiel
records_sf <- records_sf %>%
  mutate(
    speed = runif(n = n(), min = 0, max = 60),  # Zufällige Geschwindigkeit zwischen 0 und 60 km/h
    activity = if_else(runif(n = n()) > 0.5, "moving", "pause")  # Zufällige Aktivitätszuweisung
  )

# Plot für Geschwindigkeit über Zeit mit Pausen
# moving_speed_plot_with_pauses <- 
  ggplot() +
  geom_line(data = filter(records_sf, activity == "moving"),
            aes(x = timestamp, y = speed, color = "Moving")) +
  geom_point(data = filter(records_sf, activity == "pause"),
             aes(x = timestamp, y = speed, color = "Pause")) +
  scale_color_manual(values = c("Moving" = "blue", "Pause" = "red")) +
  labs(title = "Speed Over Time (Movement and Pauses)", x = "Time", y = "Speed (km/h)") +
  theme_minimal()

# Drucken des Plots
# print(moving_speed_plot_with_pauses)
```

#Heatmap

```{r}
names(records_sf)



# Erstellen einer Heatmap der Bewegungsdaten
# heatmap_movement <- 
  ggplot(records_sf, aes(x = lon_copy , y = lat_copy )) +
  stat_density2d(aes(fill = after_stat(level)), geom = "polygon") +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(title = "Heatmap der Bewegungsdaten", x = "Longitude", y = "Latitude") +
  theme_minimal() +
    facet_grid( . ~ Person)

# Drucken der Heatmap
# print(heatmap_movement)



# Summarisieren von häufigen Aufenthaltsorten basierend auf deinen vorhandenen Koordinaten 

frequent_locations <- 
  records_sf %>%
  group_by(Person, lon_copy, lat_copy) %>%
  summarise(count = n(), .groups = 'drop') %>%
  arrange(desc(count))

# Visualisierung der häufigen Aufenthaltsorte
# frequent_locations_plot <- 
  ggplot(frequent_locations, aes(x = lon_copy, y = lat_copy, size = count, color = Person)) +
  geom_point(alpha = 0.6) +
  labs(title = "Häufige Aufenthaltsorte", x = "Longitude", y = "Latitude") +
  theme_minimal()


  
# # Drucken des Plots
# print(frequent_locations_plot)
# 
# 
# # Print the plot
# print(frequent_locations_plot)
# 
# 
# # Print the heatmap
# print(heatmap_movement)



```

#Plots

```{r}


 ##  Koordinaten ##
# Plot der Longitude und Latitude
ggplot(records_sf, aes(x = lat_copy, y = lon_copy, color = activity)) +
  geom_point() +
  labs(title = "Plot der Koordinaten (Longitude und Latitude) nach Aktivität") +
  theme_minimal() +
  facet_grid( . ~ Person )


# Plot der Longitude und Latitude

#Serafin
records_sf |>  
  filter(Person == "Serafin") |> 
ggplot(aes(x = lat_copy, y = lon_copy)) +
  geom_point() +
  labs(title = "Koordinaten der besuchten Orte oder Aktivität von Serafin") +
  theme_minimal() +
  facet_grid( . ~ Person )


#Nadja
records_sf |>  
  filter(Person == "Nadja") |> 
ggplot(aes(x = lat_copy, y = lon_copy)) +
  geom_point() +
  labs(title = "Koordinaten der besuchten Orte oder Aktivität von Nadja") +
  theme_minimal() +
  facet_grid( . ~ Person )



# Plot der Longitude und Latitude
ggplot(records_sf, aes(x = lat_copy, y = lon_copy, color = Person)) +
  geom_point() +
  labs(title = "Koordinaten nach Person") +
  theme_minimal()






 ##  Zeitlich ##

# #mit Geschwindigkeit
# # # Plot der Longitude und Latitude
# ggplot(records_sf, aes(x = day, y = Speed_kmh, color = Person )) +
#   geom_point() +
#   labs(title = "Erreichte Geschwindigkeiten der Personen") +
#   theme_minimal()
# 
# ggplot(records_sf, aes(x = day, y = Speed_kmh, color = Person )) +
#   geom_boxplot() +
#   labs(title = "Erreichte Geschwindigkeiten der Personen") +
#   theme_minimal()
# 
# 
# ggplot(records_sf, aes(x = Person, y = Speed_kmh)) +
#   geom_boxplot() +
#   labs(title = "Erreichte Geschwindigkeiten der Personen über Untersuchungszeitraum") +
#   theme_minimal()





### Plot mit x-Achse Zeit, y-Achse Koordinate (Long, Lat) und color = Person ###
#wie kann man Longitude und Latitude auf der y-Achse darstellen?






## Anzahl Aktivitäten

  
# ggplot(records_sf, aes(x = lat_copy, y = lon_copy, color = Person)) +
#   geom_point() +
#   geom_text(aes(label = Placemark), vjust = -1, size = 3) +  # Punkte mit Text aus der Spalte 'Placemark' beschriften
#   labs(title = "Plot der Koordinaten (Longitude und Latitude) nach Person") +
#   theme_minimal()




# Add plotting for Speed Over Time where movement occurred, highlighting pauses
# moving_speed_plot_with_pauses <- 

# ggplot() +
#   geom_line(data = filter(records_sf, activity == "moving"),
#             aes(x = time, y = speed, color = activity)) +
#   geom_point(data = filter(records_sf, activity == "pause"),
#              aes(x = time, y = speed, color = activity)) +
#   scale_color_manual(values = c("moving" = "blue", "pause" = "red")) +
#   labs(title = "Speed Over Time (Movement and Pauses)", x = "Time", y = "Speed (km/h)") +
#   theme_minimal() +
#   facet_grid(  Person  ~ .)





#Hotspot
ggplot(records_sf, aes(x = lon_copy, y = lat_copy)) +
  stat_density2d(aes(fill = ..level..), geom = "polygon") +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(title = "Heatmap der Bewegungsdaten", x = "Longitude", y = "Latitude") +
  facet_grid(  .  ~ Person)



# 
# 
# # Häufige Aufenthaltsorte 
# frequent_locations <- records_sf %>%
#   group_by(Person, lon_copy, lat_copy) %>%
#   summarise(count = n()) %>%
#   arrange(desc(count))
# 
# 
# 
# # Visualisierung der häufigen Aufenthaltsorte
# ggplot(frequent_locations, aes(x = lon_copy, y = lat_copy, size = count, color = Person)) +
#   geom_point(alpha = 0.6) +
#   labs(title = "Häufige Aufenthaltsorte", x = "Longitude", y = "Latitude") +
#   theme_minimal() 


```

#Meeting_Points

```{r}
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(geosphere)
library(tmap)
library(lubridate)
library(readr)

# Define the file path for the CSV file
csv_path <- "C:/Users/nadja/OneDrive - ZHAW/General/Projektarbeit/R/PatTre/Data/csv_data_moving_pause.csv"

# Read the CSV file
csv_data <- read_csv(csv_path)

# Convert the time column to POSIXct
records_sf_Timepoint <- csv_data %>%
  mutate(Time_Point = as.POSIXct(Time_Point, format = "%Y-%m-%dT%H:%M:%OS", tz = "UTC"))

str(records_sf_Timepoint$Time_Point)

# Round the time to the nearest 15 minutes
records_sf_Timepoint_rounded <- records_sf_Timepoint %>%
  mutate(Time_Rounded = round_date(Time_Point, unit = "15 minutes"))

# Split data into separate data frames for each person
serafin_data <- records_sf_Timepoint_rounded %>% filter(Person == "Serafin") %>% as.data.frame()
nadja_data <- records_sf_Timepoint_rounded %>% filter(Person == "Nadja") %>% as.data.frame()

# Join the datasets by the rounded time
joined_data <- inner_join(serafin_data, nadja_data, by = "Time_Rounded", suffix = c(".Serafin", ".Nadja"))

names(joined_data)

# Calculate Euclidean distances between concurrent observations
joined_data <- joined_data %>%
  mutate(Distance = sqrt((Longitude_LV95.Serafin - Longitude_LV95.Nadja)^2 + 
                         (Latitude_LV95.Serafin - Latitude_LV95.Nadja)^2))

# Radius der Erde in Kilometern
earth_radius <- 6371

# Berechnung der Haversine-Distanz um von Grad auf Kilometer zu kommen
joined_data <- joined_data %>%
  mutate(
    Distance_km = 2 * earth_radius * asin(sqrt(
      sin((Latitude_LV95.Nadja - Latitude_LV95.Serafin) * pi / 180 / 2)^2 +
      cos(Latitude_LV95.Serafin * pi / 180) * cos(Latitude_LV95.Nadja * pi / 180) *
      sin((Longitude_LV95.Nadja - Longitude_LV95.Serafin) * pi / 180 / 2)^2
    ))
  )

# Meet als Radius von 250 Metern
# Determine if the persons are spatially close enough to constitute a meet (within 250 meters)
joined_data <- joined_data %>%
  mutate(Meet = Distance_km <= 0.25)

# Filter the joined dataset to only include meets
meets_data <- joined_data %>% filter(Meet == TRUE)

# Create a table with the meeting points, coordinates, and times
meeting_table <- meets_data %>%
  mutate(Meeting_Longitude = (Longitude_LV95.Serafin + Longitude_LV95.Nadja) / 2,
         Meeting_Latitude = (Latitude_LV95.Serafin + Latitude_LV95.Nadja) / 2) %>%
  select(Time_Rounded, Meeting_Longitude, Meeting_Latitude)

# Print the meeting table
print(meeting_table)

# Plot the meeting points with coordinates and times
plot <- ggplot(meeting_table, aes(x = Meeting_Longitude, y = Meeting_Latitude)) +
  geom_point(color = "pink", size = 2, alpha = 0.7) +
  labs(title = "Meeting Points between Serafin and Nadja (within 250m)",
       x = "Longitude (LV95)",
       y = "Latitude (LV95)") +
  theme_minimal()

# Display the plot
print(plot)

# Create a map using leaflet to display the meets
leaflet(data = meeting_table) %>%
  addProviderTiles(providers$Stamen.TonerLite, options = providerTileOptions(noWrap = TRUE)) %>%
  addCircleMarkers(lng = ~Meeting_Longitude,
                   lat = ~Meeting_Latitude,
                   color = "pink",
                   radius = 5,
                   popup = ~paste("Time:", Time_Rounded)) %>%
  addLegend("bottomright", colors = "pink", labels = "Meet Points", title = "Legend")

# Daten in ein sf-Objekt umwandeln
meeting_table_sf <- st_as_sf(meeting_table, coords = c("Meeting_Longitude", "Meeting_Latitude"), crs = 4326)

# Karte mit tmap
tmap_mode("view")
tm_shape(meeting_table_sf) +
  tm_dots(col = "pink", size = 0.1) +
  tm_text("Time_Rounded", just = "left", xmod = 0.5) +
  tm_basemap("OpenStreetMap")

# Meet als Radius von 500 Metern
# Determine if the persons are spatially close enough to constitute a meet
joined_data <- joined_data %>%
  mutate(Meet = Distance_km <= 0.5)

# Filter the joined dataset to only include meets
meets_data <- joined_data %>% filter(Meet == TRUE)

# Create a table with the meeting points, coordinates, and times
meeting_table <- meets_data %>%
  mutate(Meeting_Longitude = (Longitude_LV95.Serafin + Longitude_LV95.Nadja) / 2,
         Meeting_Latitude = (Latitude_LV95.Serafin + Latitude_LV95.Nadja) / 2) %>%
  select(Time_Rounded, Meeting_Longitude, Meeting_Latitude)

# Print the meeting table
print(meeting_table)

# Plot the meeting points with coordinates and times
plot <- ggplot(meeting_table, aes(x = Meeting_Longitude, y = Meeting_Latitude)) +
  geom_point(color = "pink", size = 2, alpha = 0.7) +
  labs(title = "Meeting Points between Serafin and Nadja (within 500m)",
       x = "Longitude (LV95)",
       y = "Latitude (LV95)") +
  theme_minimal()

# Display the plot
print(plot)

# Daten in ein sf-Objekt umwandeln
meeting_table_sf <- st_as_sf(meeting_table, coords = c("Meeting_Longitude", "Meeting_Latitude"), crs = 4326)

# Karte mit tmap
tmap_mode("view")
tm_shape(meeting_table_sf) +
  tm_dots(col = "pink", size = 0.1) +
  tm_text("Time_Rounded", just = "left", xmod = 0.5) +
  tm_basemap("OpenStreetMap")

# Meet als Radius von 100 Metern
# Determine if the persons are spatially close enough to constitute a meet
joined_data <- joined_data %>%
  mutate(Meet = Distance_km <= 0.1)

# Filter the joined dataset to only include meets
meets_data <- joined_data %>% filter(Meet == TRUE)

# Create a table with the meeting points, coordinates, and times
meeting_table <- meets_data %>%
  mutate(Meeting_Longitude = (Longitude_LV95.Serafin + Longitude_LV95.Nadja) / 2,
         Meeting_Latitude = (Latitude_LV95.Serafin + Latitude_LV95.Nadja) / 2) %>%
  select(Time_Rounded, Meeting_Longitude, Meeting_Latitude)

# Print the meeting table
print(meeting_table)

# Plot the meeting points with coordinates and times
plot <- ggplot(meeting_table, aes(x = Meeting_Longitude, y = Meeting_Latitude)) +
  geom_point(color = "pink", size = 2, alpha = 0.7) +
  labs(title = "Meeting Points between Serafin and Nadja (within 100m)",
       x = "Longitude (LV95)",
       y = "Latitude (LV95)") +
  theme_minimal()

# Display the plot
print(plot)

# Daten in ein sf-Objekt umwandeln
meeting_table_sf <- st_as_sf(meeting_table, coords = c("Meeting_Longitude", "Meeting_Latitude"), crs = 4326)

# Karte mit tmap
tmap_mode("view")
tm_shape(meeting_table_sf) +
  tm_dots(col = "pink", size = 0.1) +
  tm_text("Time_Rounded", just = "left", xmod = 0.5) +
  tm_basemap("OpenStreetMap")

# Meet als Radius von 55 Metern
#näher sind keine Punkte
# Determine if the persons are spatially close enough to constitute a meet
joined_data <- joined_data %>%
  mutate(Meet = Distance_km <= 0.055)

# Filter the joined dataset to only include meets
meets_data <- joined_data %>% filter(Meet == TRUE)

# Create a table with the meeting points, coordinates, and times
meeting_table <- meets_data %>%
  mutate(Meeting_Longitude = (Longitude_LV95.Serafin + Longitude_LV95.Nadja) / 2,
         Meeting_Latitude = (Latitude_LV95.Serafin + Latitude_LV95.Nadja) / 2) %>%
  select(Time_Rounded, Meeting_Longitude, Meeting_Latitude)

# Print the meeting table
print(meeting_table)

# Plot the meeting points with coordinates and times
plot <- ggplot(meeting_table, aes(x = Meeting_Longitude, y = Meeting_Latitude)) +
  geom_point(color = "pink", size = 2, alpha = 0.7) +
  labs(title = "Meeting Points between Serafin and Nadja (within 55m)",
       x = "Longitude (LV95)",
       y = "Latitude (LV95)") +
  theme_minimal()

# Display the plot
print(plot)

# Daten in ein sf-Objekt umwandeln
meeting_table_sf <- st_as_sf(meeting_table, coords = c("Meeting_Longitude", "Meeting_Latitude"), crs = 4326)

# Karte mit tmap
tmap_mode("view")
tm_shape(meeting_table_sf) +
  tm_dots(col = "pink", size = 0.1) +
  tm_text("Time_Rounded", just = "left", xmod = 0.5) +
  tm_basemap("OpenStreetMap")

# Load the Swiss boundaries shapefile
swiss_boundaries <- st_read("C:/Users/nadja/OneDrive - ZHAW/General/Projektarbeit/Ausgangsdaten/shp_Border CH/swissBOUNDARIES3D_1_5_TLM_KANTONSGEBIET.shp")

# Ensure geometries are valid
swiss_boundaries <- st_make_valid(swiss_boundaries)

# Convert the CRS of the meeting points to match the Swiss Boundaries CRS
meeting_table_sf <- st_transform(meeting_table_sf, st_crs(swiss_boundaries))

# Plot the meeting points with the Swiss boundaries as the background using ggplot2
ggplot() +
  geom_sf(data = swiss_boundaries, fill = "white", color = "black") +
  geom_sf(data = meeting_table_sf, aes(color = Time_Rounded), size = 2, alpha = 0

```

#Meeting_Points 500m

```{r}

```


# Connected acitivities and Distances on a Day \> Map
```{r}

# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(ggspatial)
library(scales)
library(osmdata)
library(geosphere)

# Assuming you have loaded the data into records_N dataframe
# records_N <- read.csv("path_to_your_data.csv") # Adjust the path accordingly

# Filter records by timestamp for the specific date
records_filtered <- records_N %>%
  filter(grepl("2024-05-24", timestamp))

# Parse the activity column
records_filtered <- records_filtered %>%
  mutate(activity = gsub("list\\(list\\(type = c\\(|\\), confidence = c\\(|\\)\\)\\)", "", activity)) %>%
  separate(activity, into = c("activity1", "activity2"), sep = ", confidence = ") %>%
  separate(activity1, into = c("activity1", "activity1_confidence"), sep = ", ") %>%
  separate(activity2, into = c("activity2", "activity2_confidence"), sep = ", ")

# Convert lat/lon from E7 to decimal degrees
records_filtered <- records_filtered %>%
  mutate(latitude = latitudeE7 / 1e7,
         longitude = longitudeE7 / 1e7)

# Remove activities "Null" and "Still"
records_filtered <- records_filtered %>%
  filter(!activity1 %in% c("Null", "Still"))

# Convert to spatial dataframe
sf_records_filtered <- st_as_sf(records_filtered, coords = c("longitude", "latitude"), crs = 4326)

# Calculate distances between consecutive points
records_filtered <- records_filtered %>%
  arrange(timestamp) %>%
  mutate(dist = distHaversine(cbind(longitude, latitude), cbind(lag(longitude), lag(latitude))) / 1000) %>%
  replace_na(list(dist = 0))  # Replace NA distances with 0

# Summarize distance per activity
activity_distances <- records_filtered %>%
  group_by(activity1) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE))

# Create labels for the legend
records_filtered <- records_filtered %>%
  left_join(activity_distances, by = "activity1") %>%
  mutate(legend_label = paste(activity1, round(total_distance, 2), "km"))

# Get bounding box for the plot area
bbox <- st_bbox(sf_records_filtered)

# Get OpenStreetMap data
osm_map <- opq(bbox = c(bbox["xmin"], bbox["ymin"], bbox["xmax"], bbox["ymax"])) %>%
  add_osm_feature(key = "highway") %>%
  osmdata_sf()

# Plot using ggplot2
ggplot() +
  geom_sf(data = osm_map$osm_lines, color = "grey80", size = 0.3) + # Use osm_lines for a more detailed background
  geom_point(data = records_filtered, aes(x = longitude, y = latitude, color = legend_label), size = 2) +
  geom_path(data = records_filtered, aes(x = longitude, y = latitude, group = 1, color = legend_label), size = 1) +
  theme_minimal() +
  labs(title = "Connected Activities and Distances on 24.05.2024", 
       fill = "Activity and Distance", 
       color = "Activity and Distance")


```

# Connected acitivities and Distances on a Month \> Map mit Hintergrund CH shp

```{r}
# QUELLE HINTERGRUNDKARTE:
# https://www.swisstopo.admin.ch/de/landschaftsmodell-swissboundaries3d#swissBOUNDARIES3D---Download


# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(geosphere)

# Set SHAPE_RESTORE_SHX config option
Sys.setenv(SHAPE_RESTORE_SHX = "YES")

# Load the Swiss boundaries shapefile
swiss_boundaries <- st_read("C:/Users/nadja/OneDrive - ZHAW/General/Projektarbeit/Ausgangsdaten/shp_Border CH/swissBOUNDARIES3D_1_5_TLM_KANTONSGEBIET.shp")

# Ensure geometries are valid
swiss_boundaries <- st_make_valid(swiss_boundaries)

# Check the CRS of the shapefile
print(st_crs(swiss_boundaries))

# Assuming you have loaded the data into records_N dataframe
# records_N <- read.csv("path_to_your_data.csv") # Adjust the path accordingly

# Filter records by timestamp for the entire month of April 2024
records_filtered <- records_N %>%
  filter(grepl("2024-04", timestamp))

# Parse the activity column
records_filtered <- records_filtered %>%
  mutate(activity = gsub("list\\(list\\(type = c\\(|\\), confidence = c\\(|\\)\\)\\)", "", activity)) %>%
  separate(activity, into = c("activity1", "activity2"), sep = ", confidence = ") %>%
  separate(activity1, into = c("activity1", "activity1_confidence"), sep = ", ") %>%
  separate(activity2, into = c("activity2", "activity2_confidence"), sep = ", ")

# Convert lat/lon from E7 to decimal degrees
records_filtered <- records_filtered %>%
  mutate(latitude = latitudeE7 / 1e7,
         longitude = longitudeE7 / 1e7)

# Remove activities "Null" and "Still"
records_filtered <- records_filtered %>%
  filter(!activity1 %in% c("Null", "Still"))

# Convert to spatial dataframe
sf_records_filtered <- st_as_sf(records_filtered, coords = c("longitude", "latitude"), crs = 4326)

# Transform the CRS of the swiss boundaries to match the records
swiss_boundaries <- st_transform(swiss_boundaries, crs = st_crs(sf_records_filtered))

# Calculate distances between consecutive points
records_filtered <- records_filtered %>%
  arrange(timestamp) %>%
  mutate(dist = distHaversine(cbind(longitude, latitude), cbind(lag(longitude), lag(latitude))) / 1000) %>%
  replace_na(list(dist = 0))  # Replace NA distances with 0

# Summarize distance per activity
activity_distances <- records_filtered %>%
  group_by(activity1) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE))

# Create labels for the legend
records_filtered <- records_filtered %>%
  left_join(activity_distances, by = "activity1") %>%
  mutate(legend_label = paste(activity1, round(total_distance, 2), "km"))

# Plot using ggplot2
ggplot() +
  geom_sf(data = swiss_boundaries, fill = NA, color = "grey50") +
  geom_point(data = records_filtered, aes(x = longitude, y = latitude, color = legend_label), size = 2) +
  geom_path(data = records_filtered, aes(x = longitude, y = latitude, group = 1, color = legend_label), size = 1) +
  theme_minimal() +
  labs(title = "Connected Activities and Distances in April 2024", 
       fill = "Activity and Distance", 
       color = "Activity and Distance")






```

# Connected acitivities and Distances 2023 \> Map

```{r}
# QUELLE Hintergrundkarte: https://data.dtu.dk/articles/dataset/Shapefile_of_European_countries/23686383
# Verwendung REFNET für Transformation

#Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(geosphere)

# Set SHAPE_RESTORE_SHX config option
Sys.setenv(SHAPE_RESTORE_SHX = "YES")

# Load the Europe boundaries shapefile
europe_boundaries <- st_read("C:/Users/nadja/OneDrive - ZHAW/General/Projektarbeit/Ausgangsdaten/Europe/Europe_merged.shp")

# Ensure geometries are valid
europe_boundaries <- st_make_valid(europe_boundaries)

# Check the CRS of the shapefile
print(st_crs(europe_boundaries))

# Assuming you have loaded the data into records_N dataframe
# records_N <- read.csv("path_to_your_data.csv") # Adjust the path accordingly

# Filter records by timestamp for the entire month of April 2024
records_filtered <- records_N %>%
  filter(grepl("2023", timestamp))

# Parse the activity column
records_filtered <- records_filtered %>%
  mutate(activity = gsub("list\\(list\\(type = c\\(|\\), confidence = c\\(|\\)\\)\\)", "", activity)) %>%
  separate(activity, into = c("activity1", "activity2"), sep = ", confidence = ") %>%
  separate(activity1, into = c("activity1", "activity1_confidence"), sep = ", ") %>%
  separate(activity2, into = c("activity2", "activity2_confidence"), sep = ", ")

# Convert lat/lon from E7 to decimal degrees
records_filtered <- records_filtered %>%
  mutate(latitude = latitudeE7 / 1e7,
         longitude = longitudeE7 / 1e7)

# Remove activities "Null" and "Still"
records_filtered <- records_filtered %>%
  filter(!activity1 %in% c("Null", "Still"))

# Convert to spatial dataframe
sf_records_filtered <- st_as_sf(records_filtered, coords = c("longitude", "latitude"), crs = 4326)

# Transform the CRS of the Europe boundaries to match the records
europe_boundaries <- st_transform(europe_boundaries, crs = st_crs(sf_records_filtered))

# Calculate distances between consecutive points
records_filtered <- records_filtered %>%
  arrange(timestamp) %>%
  mutate(dist = distHaversine(cbind(longitude, latitude), cbind(lag(longitude), lag(latitude))) / 1000) %>%
  replace_na(list(dist = 0))  # Replace NA distances with 0

# Summarize distance per activity
activity_distances <- records_filtered %>%
  group_by(activity1) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE))

# Create labels for the legend
records_filtered <- records_filtered %>%
  left_join(activity_distances, by = "activity1") %>%
  mutate(legend_label = paste(activity1, round(total_distance, 2), "km"))

# Plot using ggplot2
ggplot() +
  geom_sf(data = europe_boundaries, fill = NA, color = "grey50") +
  geom_point(data = records_filtered, aes(x = longitude, y = latitude, color = legend_label), size = 2) +
  geom_path(data = records_filtered, aes(x = longitude, y = latitude, group = 1, color = legend_label), size = 1) +
  theme_minimal() +
  labs(title = "Connected Activities and Distances 2023", 
       fill = "Activity and Distance", 
       color = "Activity and Distance")


```


# Zusammenstellung Karte Europaweit

```{r}
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(scales)
library(geosphere)
library(lubridate)
library(gridExtra)
library(GGally)
library(RColorBrewer)
library(cluster)
library(factoextra)

# Load the Europe boundaries shapefile
europe_boundaries <- st_read("C:/Users/nadja/OneDrive - ZHAW/General/Projektarbeit/Ausgangsdaten/Europe/Europe_merged.shp")

# Ensure geometries are valid
europe_boundaries <- st_make_valid(europe_boundaries)

# Check the CRS of the shapefile
print(st_crs(europe_boundaries))

# Hilfsfunktion zur Klassifizierung der Tageszeit
time_of_day <- function(hour) {
  case_when(
    hour >= 6 & hour < 10 ~ "Morgen (06-10 Uhr)",
    hour >= 10 & hour < 14 ~ "Mittag (10-14 Uhr)",
    hour >= 14 & hour < 18 ~ "Nachmittag (14-18 Uhr)",
    hour >= 18 & hour < 22 ~ "Abend (18-22 Uhr)",
    TRUE ~ "Nacht (22-06 Uhr)"
  )
}

process_year_data <- function(records_filtered, year_label) {
  # Filter records by timestamp for the specified year
  records_filtered <- records_filtered %>%
    filter(grepl(year_label, timestamp))
  
  # Parse the activity column
  records_filtered <- records_filtered %>%
    mutate(activity = gsub("list\\(list\\(type = c\\(|\\), confidence = c\\(|\\)\\)", "", activity)) %>%
    separate(activity, into = c("activity1", "activity2"), sep = ", confidence = ") %>%
    separate(activity1, into = c("activity1", "activity1_confidence"), sep = ", ") %>%
    separate(activity2, into = c("activity2", "activity2_confidence"), sep = ", ")
  
  # Convert lat/lon from E7 to decimal degrees
  records_filtered <- records_filtered %>%
    mutate(latitude = latitudeE7 / 1e7,
           longitude = longitudeE7 / 1e7)
  
  # Remove activities "Null" and "Still"
  records_filtered <- records_filtered %>%
    filter(!activity1 %in% c("Null", "Still"))
  
  # Remove rows with missing latitude or longitude
  records_filtered <- records_filtered %>%
    filter(!is.na(latitude) & !is.na(longitude))
  
  # Further clean the activity1 field
  records_filtered <- records_filtered %>%
    mutate(activity1 = gsub("list\\(activity = \"|\"\\)", "", activity1)) %>%
    filter(activity1 != "NULL")

  # Convert to spatial dataframe
  sf_records_filtered <- st_as_sf(records_filtered, coords = c("longitude", "latitude"), crs = 4326)
  
  # Calculate distances between consecutive points
  records_filtered <- records_filtered %>%
    arrange(timestamp) %>%
    mutate(
      dist = distHaversine(cbind(longitude, latitude), cbind(lag(longitude), lag(latitude))) / 1000, # Convert to km
      timestamp = as.POSIXct(timestamp, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC"),
      year = year(timestamp),
      month = month(timestamp, label = TRUE, abbr = FALSE), # Monate als Namen
      day = wday(timestamp, label = TRUE, abbr = FALSE), # Wochentage als Namen
      hour = hour(timestamp),
      period = time_of_day(hour)
    ) %>%
    replace_na(list(dist = 0))  # Replace NA distances with 0
  
  return(records_filtered)
}

# Assuming records_N is loaded
records_2022 <- process_year_data(records_N, "2022")
records_2023 <- process_year_data(records_N, "2023")
records_2024 <- process_year_data(records_N, "2024")

# Combine all years
all_records <- bind_rows(records_2022, records_2023, records_2024)

# Define the order of periods and days
all_records$period <- factor(all_records$period, levels = c("Morgen (06-10 Uhr)", "Mittag (10-14 Uhr)", "Nachmittag (14-18 Uhr)", "Abend (18-22 Uhr)", "Nacht (22-06 Uhr)"))
all_records$day <- factor(all_records$day, levels = c("Montag", "Dienstag", "Mittwoch", "Donnerstag", "Freitag", "Samstag", "Sonntag"))

# Prepare data for clustering
clustering_data <- all_records %>%
  select(longitude, latitude, activity1) %>%
  mutate(activity1 = as.numeric(factor(activity1)))

# Perform k-means clustering
set.seed(123)
kmeans_result <- kmeans(clustering_data[, c("longitude", "latitude")], centers = 5)

# Add cluster information to the data
all_records$cluster <- factor(kmeans_result$cluster)

# Clustering nach Jahr
clustering_data_year <- all_records %>%
  select(longitude, latitude, year)

set.seed(123)
kmeans_result_year <- kmeans(clustering_data_year[, c("longitude", "latitude")], centers = 5)

# Add year cluster information to the data
all_records$cluster_year <- factor(kmeans_result_year$cluster)

# Visualize clusters on map with Europe boundaries
p1 <- ggplot() +
  geom_sf(data = europe_boundaries, fill = "lightgrey", color = "white") +
  geom_point(data = all_records, aes(x = longitude, y = latitude, color = cluster), size = 2, alpha = 0.6) +
  scale_color_brewer(palette = "Set3", name = "Cluster der Aktivitäten") +
  labs(
    title = "Geografische Cluster der Aktivitäten",
    x = "Längengrad",
    y = "Breitengrad"
  ) +
  theme_minimal()

# Visualize year-based clusters on map with Europe boundaries
p2 <- ggplot() +
  geom_sf(data = europe_boundaries, fill = "lightgrey", color = "white") +
  geom_point(data = all_records, aes(x = longitude, y = latitude, color = cluster_year), size = 2, alpha = 0.6) +
  scale_color_brewer(palette = "Set3", name = "Cluster nach Jahr") +
  labs(
    title = "Geografische Cluster der Aktivitäten nach Jahr",
    x = "Längengrad",
    y = "Breitengrad"
  ) +
  theme_minimal()

# Heatmap der Koordinaten nach Aktivität
p3 <- ggplot() +
  geom_sf(data = europe_boundaries, fill = "lightgrey", color = "white") +
  geom_tile(data = all_records, aes(x = longitude, y = latitude, fill = activity1), size = 5) +
  scale_fill_brewer(palette = "Set3", name = "Aktivität") +
  labs(
    title = "Heatmap der Koordinaten nach Aktivität",
    x = "Längengrad",
    y = "Breitengrad"
  ) +
  theme_minimal()

# Heatmap der Koordinaten nach Jahr
p4 <- ggplot() +
  geom_sf(data = europe_boundaries, fill = "lightgrey", color = "white") +
  geom_tile(data = all_records, aes(x = longitude, y = latitude, fill = factor(year)), size = 5) +
  scale_fill_brewer(palette = "Set3", name = "Jahr") +
  labs(
    title = "Heatmap der Koordinaten nach Jahr",
    x = "Längengrad",
    y = "Breitengrad"
  ) +
  theme_minimal()

# Arrange plots in grid
grid.arrange(
  p1, p2, p3, p4,
  ncol = 1
)
```


# Heatmap Karte Europaweit

```{r}
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(scales)
library(geosphere)
library(lubridate)
library(gridExtra)


library(GGally)
library(RColorBrewer)
library(cluster)
library(factoextra)

# Load the Europe boundaries shapefile
europe_boundaries <- st_read("C:/Users/nadja/OneDrive - ZHAW/General/Projektarbeit/Ausgangsdaten/Europe/Europe_merged.shp")

# Ensure geometries are valid
europe_boundaries <- st_make_valid(europe_boundaries)

# Check the CRS of the shapefile
print(st_crs(europe_boundaries))

# Hilfsfunktion zur Klassifizierung der Tageszeit
time_of_day <- function(hour) {
  case_when(
    hour >= 6 & hour < 10 ~ "Morgen (06-10 Uhr)",
    hour >= 10 & hour < 14 ~ "Mittag (10-14 Uhr)",
    hour >= 14 & hour < 18 ~ "Nachmittag (14-18 Uhr)",
    hour >= 18 & hour < 22 ~ "Abend (18-22 Uhr)",
    TRUE ~ "Nacht (22-06 Uhr)"
  )
}

process_year_data <- function(records_filtered, year_label) {
  # Filter records by timestamp for the specified year
  records_filtered <- records_filtered %>%
    filter(grepl(year_label, timestamp))
  
  # Parse the activity column
  records_filtered <- records_filtered %>%
    mutate(activity = gsub("list\\(list\\(type = c\\(|\\), confidence = c\\(|\\)\\)", "", activity)) %>%
    separate(activity, into = c("activity1", "activity2"), sep = ", confidence = ") %>%
    separate(activity1, into = c("activity1", "activity1_confidence"), sep = ", ") %>%
    separate(activity2, into = c("activity2", "activity2_confidence"), sep = ", ")
  
  # Convert lat/lon from E7 to decimal degrees
  records_filtered <- records_filtered %>%
    mutate(latitude = latitudeE7 / 1e7,
           longitude = longitudeE7 / 1e7)
  
  # Remove activities "Null" and "Still"
  records_filtered <- records_filtered %>%
    filter(!activity1 %in% c("Null", "Still"))
  
  # Remove rows with missing latitude or longitude
  records_filtered <- records_filtered %>%
    filter(!is.na(latitude) & !is.na(longitude))
  
  # Further clean the activity1 field
  records_filtered <- records_filtered %>%
    mutate(activity1 = gsub("list\\(activity = \"|\"\\)", "", activity1)) %>%
    filter(activity1 != "NULL")

  # Convert to spatial dataframe
  sf_records_filtered <- st_as_sf(records_filtered, coords = c("longitude", "latitude"), crs = 4326)
  
  # Calculate distances between consecutive points
  records_filtered <- records_filtered %>%
    arrange(timestamp) %>%
    mutate(
      dist = distHaversine(cbind(longitude, latitude), cbind(lag(longitude), lag(latitude))) / 1000, # Convert to km
      timestamp = as.POSIXct(timestamp, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC"),
      year = year(timestamp),
      month = month(timestamp, label = TRUE, abbr = FALSE), # Monate als Namen
      day = wday(timestamp, label = TRUE, abbr = FALSE), # Wochentage als Namen
      hour = hour(timestamp),
      period = time_of_day(hour)
    ) %>%
    replace_na(list(dist = 0))  # Replace NA distances with 0
  
  return(records_filtered)
}

# Assuming records_N is loaded
records_2022 <- process_year_data(records_N, "2022")
records_2023 <- process_year_data(records_N, "2023")
records_2024 <- process_year_data(records_N, "2024")

# Combine all years
all_records <- bind_rows(records_2022, records_2023, records_2024)

# Define the order of periods and days
all_records$period <- factor(all_records$period, levels = c("Morgen (06-10 Uhr)", "Mittag (10-14 Uhr)", "Nachmittag (14-18 Uhr)", "Abend (18-22 Uhr)", "Nacht (22-06 Uhr)"))
all_records$day <- factor(all_records$day, levels = c("Montag", "Dienstag", "Mittwoch", "Donnerstag", "Freitag", "Samstag", "Sonntag"))

# Filter data to the area with high density of points
# Adjust these limits based on your data to zoom in on the area of interest
x_limits <- c(-10, 30)
y_limits <- c(35, 65)

# Heatmap der Koordinaten nach Jahr (gezoomt auf dichten Bereich)
p_heatmap_zoom <- ggplot() +
  geom_sf(data = europe_boundaries, fill = "lightgrey", color = "white") +
  stat_density2d(data = all_records, aes(x = longitude, y = latitude, fill = after_stat(level), alpha = after_stat(level)), geom = "polygon", contour = TRUE) +
  scale_fill_viridis_c(option = "inferno", name = "Häufigkeit") +
  scale_alpha(range = c(0.4, 0.8), guide = "none") +
  coord_sf(xlim = x_limits, ylim = y_limits) +
  labs(
    title = "Heatmap der Koordinaten über die Jahre (gezoomt)",
    x = "Längengrad",
    y = "Breitengrad"
  ) +
  theme_minimal()

# Heatmap der Koordinaten nach Jahr und Jahresweise facetting (gezoomt auf dichten Bereich)
p_heatmap_facet_zoom <- ggplot() +
  geom_sf(data = europe_boundaries, fill = "lightgrey", color = "white") +
  stat_density2d(data = all_records, aes(x = longitude, y = latitude, fill = after_stat(level), alpha = after_stat(level)), geom = "polygon", contour = TRUE) +
  scale_fill_viridis_c(option = "inferno", name = "Häufigkeit") +
  scale_alpha(range = c(0.4, 0.8), guide = "none") +
  coord_sf(xlim = x_limits, ylim = y_limits) +
  facet_wrap(~ year) +
  labs(
    title = "Heatmap der Koordinaten nach Jahr (gezoomt)",
    x = "Längengrad",
    y = "Breitengrad"
  ) +
  theme_minimal()

# Arrange plots in grid
grid.arrange(
  p_heatmap_zoom, p_heatmap_facet_zoom,
  ncol = 1
)

```

# Karte Europaweit

```{r}
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(geosphere)
library(dbscan)

# Set SHAPE_RESTORE_SHX config option
Sys.setenv(SHAPE_RESTORE_SHX = "YES")

# Load the Europe boundaries shapefile
europe_boundaries <- st_read("C:/Users/nadja/OneDrive - ZHAW/General/Projektarbeit/Ausgangsdaten/Europe/Europe_merged.shp")

# Ensure geometries are valid
europe_boundaries <- st_make_valid(europe_boundaries)

# Load the data
# Assuming you have loaded the data into records_N dataframe
# records_N <- read.csv("path_to_your_data.csv") # Adjust the path accordingly

# Process data for each year
process_data <- function(data, year) {
  data %>%
    filter(grepl(as.character(year), timestamp)) %>%
    mutate(activity = gsub("list\\(list\\(type = c\\(|\\), confidence = c\\(|\\)\\)\\)", "", activity)) %>%
    separate(activity, into = c("activity1", "activity2"), sep = ", confidence = ") %>%
    separate(activity1, into = c("activity1", "activity1_confidence"), sep = ", ") %>%
    separate(activity2, into = c("activity2", "activity2_confidence"), sep = ", ") %>%
    mutate(latitude = latitudeE7 / 1e7,
           longitude = longitudeE7 / 1e7) %>%
    filter(!activity1 %in% c("Null", "Still"))
}

records_2022 <- process_data(records_N, 2022)
records_2023 <- process_data(records_N, 2023)
records_2024 <- process_data(records_N, 2024)

# Function to perform clustering and create convex hulls
create_clusters_and_hulls <- function(data) {
  # Perform DBSCAN clustering
  coords <- cbind(data$longitude, data$latitude)
  clusters <- dbscan(coords, eps = 0.01, minPts = 5)$cluster
  
  # Add clusters to data
  data$cluster <- clusters
  
  # Convert to spatial dataframe
  sf_data <- st_as_sf(data, coords = c("longitude", "latitude"), crs = 4326)
  
  # Create convex hulls
  hulls <- sf_data %>%
    group_by(cluster) %>%
    summarize(geometry = st_union(geometry)) %>%
    st_convex_hull()
  
  list(data = data, hulls = hulls)
}

clusters_hulls_2022 <- create_clusters_and_hulls(records_2022)
clusters_hulls_2023 <- create_clusters_and_hulls(records_2023)
clusters_hulls_2024 <- create_clusters_and_hulls(records_2024)

# Plot the data
plot_data <- function(europe_boundaries, clusters_hulls, year) {
  ggplot() +
    geom_sf(data = europe_boundaries, fill = NA, color = "grey50") +
    geom_point(data = clusters_hulls$data, aes(x = longitude, y = latitude, color = as.factor(cluster)), size = 2) +
    geom_sf(data = clusters_hulls$hulls, fill = NA, color = "blue", linetype = "dashed") +
    theme_minimal() +
    labs(title = paste("Connected Activities and Distances", year),
         fill = "Activity and Distance", 
         color = "Cluster")
}

plot_2022 <- plot_data(europe_boundaries, clusters_hulls_2022, 2022)
plot_2023 <- plot_data(europe_boundaries, clusters_hulls_2023, 2023)
plot_2024 <- plot_data(europe_boundaries, clusters_hulls_2024, 2024)

# Print plots
print(plot_2022)
print(plot_2023)
print(plot_2024)



```


# Zurückgelegte Distanz/Tageszeit+Monat_nur Pro Monat_pro Monat und Aktivität (2022) \> Diagramme

```{r}
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(scales)
library(geosphere)
library(lubridate)

# Hilfsfunktion zur Klassifizierung der Tageszeit
time_of_day <- function(hour) {
  case_when(
    hour >= 6 & hour < 10 ~ "Morgen (06-10 Uhr)",
    hour >= 10 & hour < 14 ~ "Mittag (10-14 Uhr)",
    hour >= 14 & hour < 18 ~ "Nachmittag (14-18 Uhr)",
    hour >= 18 & hour < 22 ~ "Abend (18-22 Uhr)",
    TRUE ~ "Nacht (22-06 Uhr)"
  )
}

# Filter records by timestamp for the year 2022
records_filtered <- records_N %>%
  filter(grepl("2022", timestamp))

# Parse the activity column
records_filtered <- records_filtered %>%
  mutate(activity = gsub("list\\(list\\(type = c\\(|\\), confidence = c\\(|\\)\\)\\)", "", activity)) %>%
  separate(activity, into = c("activity1", "activity2"), sep = ", confidence = ") %>%
  separate(activity1, into = c("activity1", "activity1_confidence"), sep = ", ") %>%
  separate(activity2, into = c("activity2", "activity2_confidence"), sep = ", ")

# Convert lat/lon from E7 to decimal degrees
records_filtered <- records_filtered %>%
  mutate(latitude = latitudeE7 / 1e7,
         longitude = longitudeE7 / 1e7)

# Remove activities "Null" and "Still"
records_filtered <- records_filtered %>%
  filter(!activity1 %in% c("Null", "Still"))

# Remove rows with missing latitude or longitude
records_filtered <- records_filtered %>%
  filter(!is.na(latitude) & !is.na(longitude))

# Convert to spatial dataframe
sf_records_filtered <- st_as_sf(records_filtered, coords = c("longitude", "latitude"), crs = 4326)

# Calculate distances between consecutive points
records_filtered <- records_filtered %>%
  arrange(timestamp) %>%
  mutate(
    dist = distHaversine(cbind(longitude, latitude), cbind(lag(longitude), lag(latitude))) / 1000, # Convert to km
    timestamp = as.POSIXct(timestamp, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC"),
    year = year(timestamp),
    month = month(timestamp, label = TRUE, abbr = FALSE), # Monate als Namen
    hour = hour(timestamp),
    period = time_of_day(hour)
  ) %>%
  replace_na(list(dist = 0))  # Replace NA distances with 0

# Summarize distance per activity and per month
activity_distances <- records_filtered %>%
  group_by(activity1) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE))

month_distances <- records_filtered %>%
  group_by(month) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE))

activity_month_distances <- records_filtered %>%
  group_by(month, activity1) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

# Create labels for the legend
records_filtered <- records_filtered %>%
  left_join(activity_distances, by = "activity1") %>%
  mutate(legend_label = paste(activity1, round(total_distance, 2), "km"))

# Reihenfolge der Tageszeiten definieren
levels_order <- c("Morgen (06-10 Uhr)", "Mittag (10-14 Uhr)", "Nachmittag (14-18 Uhr)", "Abend (18-22 Uhr)", "Nacht (22-06 Uhr)")
records_filtered$period <- factor(records_filtered$period, levels = levels_order)

# Datenanalyse für die zurückgelegte Distanz nach Tageszeit und Monat
month_period_distance <- records_filtered %>%
  group_by(month, period) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

# Visualisierung der zurückgelegten Distanz pro Tageszeit und Monat als Flächendiagramm
ggplot(month_period_distance, aes(x = period, y = total_distance, fill = month, group = month)) +
  geom_area(position = 'stack', alpha = 0.6) +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Zurückgelegte Distanz pro Tageszeit und Monat (2022)",
    subtitle = "Aufgeteilt nach Morgen, Mittag, Nachmittag, Abend und Nacht",
    x = "Tageszeit",
    y = "Distanz (km)",
    fill = "Monat"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Visualisierung der zurückgelegten Distanz pro Monat als Balkendiagramm
ggplot(month_distances, aes(x = month, y = total_distance, fill = month)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Zurückgelegte Distanz pro Monat (2022)",
    x = "Monat",
    y = "Distanz (km)",
    fill = "Monat"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Visualisierung der zurückgelegten Distanz pro Monat und Aktivität als gestapeltes Balkendiagramm
ggplot(activity_month_distances, aes(x = month, y = total_distance, fill = activity1)) +
  geom_bar(stat = "identity", position = "stack") +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Zurückgelegte Distanz pro Monat und Aktivität (2022)",
    x = "Monat",
    y = "Distanz (km)",
    fill = "Aktivität"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```

# Zurückgelegte Distanz/Tageszeit+Monat_nur Pro Monat_pro Monat und Aktivität (2023) \> Diagramme

```{r}
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(scales)
library(geosphere)
library(lubridate)

# Hilfsfunktion zur Klassifizierung der Tageszeit
time_of_day <- function(hour) {
  case_when(
    hour >= 6 & hour < 10 ~ "Morgen (06-10 Uhr)",
    hour >= 10 & hour < 14 ~ "Mittag (10-14 Uhr)",
    hour >= 14 & hour < 18 ~ "Nachmittag (14-18 Uhr)",
    hour >= 18 & hour < 22 ~ "Abend (18-22 Uhr)",
    TRUE ~ "Nacht (22-06 Uhr)"
  )
}

# Filter records by timestamp for the year 2023
records_filtered <- records_N %>%
  filter(grepl("2023", timestamp))

# Parse the activity column
records_filtered <- records_filtered %>%
  mutate(activity = gsub("list\\(list\\(type = c\\(|\\), confidence = c\\(|\\)\\)\\)", "", activity)) %>%
  separate(activity, into = c("activity1", "activity2"), sep = ", confidence = ") %>%
  separate(activity1, into = c("activity1", "activity1_confidence"), sep = ", ") %>%
  separate(activity2, into = c("activity2", "activity2_confidence"), sep = ", ")

# Convert lat/lon from E7 to decimal degrees
records_filtered <- records_filtered %>%
  mutate(latitude = latitudeE7 / 1e7,
         longitude = longitudeE7 / 1e7)

# Remove activities "Null" and "Still"
records_filtered <- records_filtered %>%
  filter(!activity1 %in% c("Null", "Still"))

# Convert to spatial dataframe
sf_records_filtered <- st_as_sf(records_filtered, coords = c("longitude", "latitude"), crs = 4326)

# Calculate distances between consecutive points
records_filtered <- records_filtered %>%
  arrange(timestamp) %>%
  mutate(
    dist = distHaversine(cbind(longitude, latitude), cbind(lag(longitude), lag(latitude))) / 1000, # Convert to km
    timestamp = as.POSIXct(timestamp, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC"),
    year = year(timestamp),
    month = month(timestamp, label = TRUE, abbr = FALSE), # Monate als Namen
    hour = hour(timestamp),
    period = time_of_day(hour)
  ) %>%
  replace_na(list(dist = 0))  # Replace NA distances with 0

# Summarize distance per activity and per month
activity_distances <- records_filtered %>%
  group_by(activity1) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE))

month_distances <- records_filtered %>%
  group_by(month) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE))

activity_month_distances <- records_filtered %>%
  group_by(month, activity1) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

# Create labels for the legend
records_filtered <- records_filtered %>%
  left_join(activity_distances, by = "activity1") %>%
  mutate(legend_label = paste(activity1, round(total_distance, 2), "km"))

# Reihenfolge der Tageszeiten definieren
levels_order <- c("Morgen (06-10 Uhr)", "Mittag (10-14 Uhr)", "Nachmittag (14-18 Uhr)", "Abend (18-22 Uhr)", "Nacht (22-06 Uhr)")
records_filtered$period <- factor(records_filtered$period, levels = levels_order)

# Datenanalyse für die zurückgelegte Distanz nach Tageszeit und Monat
month_period_distance <- records_filtered %>%
  group_by(month, period) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

# Visualisierung der zurückgelegten Distanz pro Tageszeit und Monat als Flächendiagramm
ggplot(month_period_distance, aes(x = period, y = total_distance, fill = month, group = month)) +
  geom_area(position = 'stack', alpha = 0.6) +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Zurückgelegte Distanz pro Tageszeit und Monat (2023)",
    subtitle = "Aufgeteilt nach Morgen, Mittag, Nachmittag, Abend und Nacht",
    x = "Tageszeit",
    y = "Distanz (km)",
    fill = "Monat"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Visualisierung der zurückgelegten Distanz pro Monat als Balkendiagramm
ggplot(month_distances, aes(x = month, y = total_distance, fill = month)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Zurückgelegte Distanz pro Monat (2023)",
    x = "Monat",
    y = "Distanz (km)",
    fill = "Monat"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Visualisierung der zurückgelegten Distanz pro Monat und Aktivität als gestapeltes Balkendiagramm
ggplot(activity_month_distances, aes(x = month, y = total_distance, fill = activity1)) +
  geom_bar(stat = "identity", position = "stack") +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Zurückgelegte Distanz pro Monat und Aktivität (2023)",
    x = "Monat",
    y = "Distanz (km)",
    fill = "Aktivität"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```

# Zurückgelegte Distanz/Tageszeit+Monat_nur Pro Monat_pro Monat und Aktivität (2024) \> Diagramme

```{r}

# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(scales)
library(geosphere)
library(lubridate)

# Hilfsfunktion zur Klassifizierung der Tageszeit
time_of_day <- function(hour) {
  case_when(
    hour >= 6 & hour < 10 ~ "Morgen (06-10 Uhr)",
    hour >= 10 & hour < 14 ~ "Mittag (10-14 Uhr)",
    hour >= 14 & hour < 18 ~ "Nachmittag (14-18 Uhr)",
    hour >= 18 & hour < 22 ~ "Abend (18-22 Uhr)",
    TRUE ~ "Nacht (22-06 Uhr)"
  )
}

# Filter records by timestamp for the year 2024
records_filtered <- records_N %>%
  filter(grepl("2024", timestamp))

# Parse the activity column
records_filtered <- records_filtered %>%
  mutate(activity = gsub("list\\(list\\(type = c\\(|\\), confidence = c\\(|\\)\\)\\)", "", activity)) %>%
  separate(activity, into = c("activity1", "activity2"), sep = ", confidence = ") %>%
  separate(activity1, into = c("activity1", "activity1_confidence"), sep = ", ") %>%
  separate(activity2, into = c("activity2", "activity2_confidence"), sep = ", ")

# Convert lat/lon from E7 to decimal degrees
records_filtered <- records_filtered %>%
  mutate(latitude = latitudeE7 / 1e7,
         longitude = longitudeE7 / 1e7)

# Remove activities "Null" and "Still"
records_filtered <- records_filtered %>%
  filter(!activity1 %in% c("Null", "Still"))

# Remove rows with missing latitude or longitude
records_filtered <- records_filtered %>%
  filter(!is.na(latitude) & !is.na(longitude))

# Convert to spatial dataframe
sf_records_filtered <- st_as_sf(records_filtered, coords = c("longitude", "latitude"), crs = 4326)

# Calculate distances between consecutive points
records_filtered <- records_filtered %>%
  arrange(timestamp) %>%
  mutate(
    dist = distHaversine(cbind(longitude, latitude), cbind(lag(longitude), lag(latitude))) / 1000, # Convert to km
    timestamp = as.POSIXct(timestamp, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC"),
    year = year(timestamp),
    month = month(timestamp, label = TRUE, abbr = FALSE), # Monate als Namen
    hour = hour(timestamp),
    period = time_of_day(hour)
  ) %>%
  replace_na(list(dist = 0))  # Replace NA distances with 0

# Summarize distance per activity and per month
activity_distances <- records_filtered %>%
  group_by(activity1) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE))

month_distances <- records_filtered %>%
  group_by(month) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE))

activity_month_distances <- records_filtered %>%
  group_by(month, activity1) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

# Create labels for the legend
records_filtered <- records_filtered %>%
  left_join(activity_distances, by = "activity1") %>%
  mutate(legend_label = paste(activity1, round(total_distance, 2), "km"))

# Reihenfolge der Tageszeiten definieren
levels_order <- c("Morgen (06-10 Uhr)", "Mittag (10-14 Uhr)", "Nachmittag (14-18 Uhr)", "Abend (18-22 Uhr)", "Nacht (22-06 Uhr)")
records_filtered$period <- factor(records_filtered$period, levels = levels_order)

# Datenanalyse für die zurückgelegte Distanz nach Tageszeit und Monat
month_period_distance <- records_filtered %>%
  group_by(month, period) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

# Visualisierung der zurückgelegten Distanz pro Tageszeit und Monat als Flächendiagramm
ggplot(month_period_distance, aes(x = period, y = total_distance, fill = month, group = month)) +
  geom_area(position = 'stack', alpha = 0.6) +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Zurückgelegte Distanz pro Tageszeit und Monat (2024)",
    subtitle = "Aufgeteilt nach Morgen, Mittag, Nachmittag, Abend und Nacht",
    x = "Tageszeit",
    y = "Distanz (km)",
    fill = "Monat"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Visualisierung der zurückgelegten Distanz pro Monat als Balkendiagramm
ggplot(month_distances, aes(x = month, y = total_distance, fill = month)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Zurückgelegte Distanz pro Monat (2024)",
    x = "Monat",
    y = "Distanz (km)",
    fill = "Monat"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Visualisierung der zurückgelegten Distanz pro Monat und Aktivität als gestapeltes Balkendiagramm
ggplot(activity_month_distances, aes(x = month, y = total_distance, fill = activity1)) +
  geom_bar(stat = "identity", position = "stack") +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Zurückgelegte Distanz pro Monat und Aktivität (2024)",
    x = "Monat",
    y = "Distanz (km)",
    fill = "Aktivität"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

# Zusammenstellung Zurückgelegte Distanz/Tageszeit+Monat_nur Pro Monat_pro Monat und Aktivität (2022-2014) \> Diagramme Nadja

```{r}
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(scales)
library(geosphere)
library(lubridate)
library(gridExtra)

# Hilfsfunktion zur Klassifizierung der Tageszeit
time_of_day <- function(hour) {
  case_when(
    hour >= 6 & hour < 10 ~ "Morgen (06-10 Uhr)",
    hour >= 10 & hour < 14 ~ "Mittag (10-14 Uhr)",
    hour >= 14 & hour < 18 ~ "Nachmittag (14-18 Uhr)",
    hour >= 18 & hour < 22 ~ "Abend (18-22 Uhr)",
    TRUE ~ "Nacht (22-06 Uhr)"
  )
}

plot_distance_per_time_of_day_and_month <- function(records_filtered, year_label) {
  # Filter records by timestamp for the specified year
  records_filtered <- records_filtered %>%
    filter(grepl(year_label, timestamp))
  
  # Parse the activity column
  records_filtered <- records_filtered %>%
    mutate(activity = gsub("list\\(list\\(type = c\\(|\\), confidence = c\\(|\\)\\)", "", activity)) %>%
    separate(activity, into = c("activity1", "activity2"), sep = ", confidence = ") %>%
    separate(activity1, into = c("activity1", "activity1_confidence"), sep = ", ") %>%
    separate(activity2, into = c("activity2", "activity2_confidence"), sep = ", ")
  
  # Convert lat/lon from E7 to decimal degrees
  records_filtered <- records_filtered %>%
    mutate(latitude = latitudeE7 / 1e7,
           longitude = longitudeE7 / 1e7)
  
  # Remove activities "Null" and "Still"
  records_filtered <- records_filtered %>%
    filter(!activity1 %in% c("Null", "Still"))
  
  # Remove rows with missing latitude or longitude
  records_filtered <- records_filtered %>%
    filter(!is.na(latitude) & !is.na(longitude))
  
  # Convert to spatial dataframe
  sf_records_filtered <- st_as_sf(records_filtered, coords = c("longitude", "latitude"), crs = 4326)
  
  # Calculate distances between consecutive points
  records_filtered <- records_filtered %>%
    arrange(timestamp) %>%
    mutate(
      dist = distHaversine(cbind(longitude, latitude), cbind(lag(longitude), lag(latitude))) / 1000, # Convert to km
      timestamp = as.POSIXct(timestamp, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC"),
      year = year(timestamp),
      month = month(timestamp, label = TRUE, abbr = FALSE), # Monate als Namen
      hour = hour(timestamp),
      period = time_of_day(hour)
    ) %>%
    replace_na(list(dist = 0))  # Replace NA distances with 0
  
  # Reorder periods
  records_filtered$period <- factor(records_filtered$period, levels = c("Morgen (06-10 Uhr)", "Mittag (10-14 Uhr)", "Nachmittag (14-18 Uhr)", "Abend (18-22 Uhr)", "Nacht (22-06 Uhr)"))
  
  # Datenanalyse für die zurückgelegte Distanz nach Tageszeit und Monat
  month_period_distance <- records_filtered %>%
    group_by(month, period) %>%
    summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')
  
  # Visualisierung der zurückgelegten Distanz pro Tageszeit und Monat als Flächendiagramm
  p1 <- ggplot(month_period_distance, aes(x = period, y = total_distance, fill = month, group = month)) +
    geom_area(position = 'stack', alpha = 0.6) +
    scale_fill_brewer(palette = "Set3") +
    labs(
      title = paste("Zurückgelegte Distanz pro Tageszeit und Monat (", year_label, ")", sep = ""),
      subtitle = "Aufgeteilt nach Morgen, Mittag, Nachmittag, Abend und Nacht",
      x = "Tageszeit",
      y = "Distanz (km)",
      fill = "Monat"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # Summarize distance per month
  month_distances <- records_filtered %>%
    group_by(month) %>%
    summarize(total_distance = sum(dist, na.rm = TRUE))
  
  # Visualisierung der zurückgelegten Distanz pro Monat als Balkendiagramm
  p2 <- ggplot(month_distances, aes(x = month, y = total_distance, fill = month)) +
    geom_bar(stat = "identity") +
    scale_fill_brewer(palette = "Set3") +
    labs(
      title = paste("Zurückgelegte Distanz pro Monat (", year_label, ")", sep = ""),
      x = "Monat",
      y = "Distanz (km)",
      fill = "Monat"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # Summarize distance per activity and per month
  activity_month_distances <- records_filtered %>%
    group_by(month, activity1) %>%
    summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')
  
  # Visualisierung der zurückgelegten Distanz pro Monat und Aktivität als gestapeltes Balkendiagramm
  p3 <- ggplot(activity_month_distances, aes(x = month, y = total_distance, fill = activity1)) +
    geom_bar(stat = "identity", position = "stack") +
    scale_fill_brewer(palette = "Set3") +
    labs(
      title = paste("Zurückgelegte Distanz pro Monat und Aktivität (", year_label, ")", sep = ""),
      x = "Monat",
      y = "Distanz (km)",
      fill = "Aktivität"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  return(list(p1, p2, p3))
}

# Assuming records_N is loaded
plots_2022 <- plot_distance_per_time_of_day_and_month(records_N, "2022")
plots_2023 <- plot_distance_per_time_of_day_and_month(records_N, "2023")
plots_2024 <- plot_distance_per_time_of_day_and_month(records_N, "2024")

# Arrange plots in grid
grid.arrange(
  grobs = c(plots_2022, plots_2023, plots_2024),
  ncol = 3
)


```

#Auswertungen einfache

```{r}
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(scales)
library(geosphere)
library(lubridate)
library(gridExtra)
library(GGally)
library(RColorBrewer)

# Hilfsfunktion zur Klassifizierung der Tageszeit
time_of_day <- function(hour) {
  case_when(
    hour >= 6 & hour < 10 ~ "Morgen (06-10 Uhr)",
    hour >= 10 & hour < 14 ~ "Mittag (10-14 Uhr)",
    hour >= 14 & hour < 18 ~ "Nachmittag (14-18 Uhr)",
    hour >= 18 & hour < 22 ~ "Abend (18-22 Uhr)",
    TRUE ~ "Nacht (22-06 Uhr)"
  )
}

process_year_data <- function(records_filtered, year_label) {
  # Filter records by timestamp for the specified year
  records_filtered <- records_filtered %>%
    filter(grepl(year_label, timestamp))
  
  # Parse the activity column
  records_filtered <- records_filtered %>%
    mutate(activity = gsub("list\\(list\\(type = c\\(|\\), confidence = c\\(|\\)\\)", "", activity)) %>%
    separate(activity, into = c("activity1", "activity2"), sep = ", confidence = ") %>%
    separate(activity1, into = c("activity1", "activity1_confidence"), sep = ", ") %>%
    separate(activity2, into = c("activity2", "activity2_confidence"), sep = ", ")
  
  # Convert lat/lon from E7 to decimal degrees
  records_filtered <- records_filtered %>%
    mutate(latitude = latitudeE7 / 1e7,
           longitude = longitudeE7 / 1e7)
  
  # Remove activities "Null" and "Still"
  records_filtered <- records_filtered %>%
    filter(!activity1 %in% c("Null", "Still"))
  
  # Remove rows with missing latitude or longitude
  records_filtered <- records_filtered %>%
    filter(!is.na(latitude) & !is.na(longitude))
  
  # Convert to spatial dataframe
  sf_records_filtered <- st_as_sf(records_filtered, coords = c("longitude", "latitude"), crs = 4326)
  
  # Calculate distances between consecutive points
  records_filtered <- records_filtered %>%
    arrange(timestamp) %>%
    mutate(
      dist = distHaversine(cbind(longitude, latitude), cbind(lag(longitude), lag(latitude))) / 1000, # Convert to km
      timestamp = as.POSIXct(timestamp, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC"),
      year = year(timestamp),
      month = month(timestamp, label = TRUE, abbr = FALSE), # Monate als Namen
      hour = hour(timestamp),
      period = time_of_day(hour)
    ) %>%
    replace_na(list(dist = 0))  # Replace NA distances with 0
  
  return(records_filtered)
}

# Assuming records_N is loaded
records_2022 <- process_year_data(records_N, "2022")
records_2023 <- process_year_data(records_N, "2023")
records_2024 <- process_year_data(records_N, "2024")

# Combine all years
all_records <- bind_rows(records_2022, records_2023, records_2024)

# Define the order of periods
all_records$period <- factor(all_records$period, levels = c("Morgen (06-10 Uhr)", "Mittag (10-14 Uhr)", "Nachmittag (14-18 Uhr)", "Abend (18-22 Uhr)", "Nacht (22-06 Uhr)"))

# Analyse Verteilung, Korrelation und Trend

# Verteilung der zurückgelegten Distanz nach Tageszeit und Jahr
dist_by_period_year <- all_records %>%
  group_by(year, period) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

p1 <- ggplot(dist_by_period_year, aes(x = period, y = total_distance, fill = factor(year))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Verteilung der zurückgelegten Distanz nach Tageszeit und Jahr",
    x = "Tageszeit",
    y = "Distanz (km)",
    fill = "Jahr"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Verteilung der zurückgelegten Distanz nach Monat und Jahr
dist_by_month_year <- all_records %>%
  group_by(year, month) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

p2 <- ggplot(dist_by_month_year, aes(x = month, y = total_distance, fill = factor(year))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Verteilung der zurückgelegten Distanz nach Monat und Jahr",
    x = "Monat",
    y = "Distanz (km)",
    fill = "Jahr"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Korrelation zwischen Monat und zurückgelegter Distanz für jedes Jahr
cor_by_year <- all_records %>%
  group_by(year, month) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop') %>%
  group_by(year) %>%
  summarize(correlation = cor(as.numeric(month), total_distance))

p3 <- ggplot(cor_by_year, aes(x = factor(year), y = correlation, color = factor(year), group = 1)) +
  geom_line(size = 1.5) +
  geom_point(size = 4) +
  scale_color_brewer(palette = "Set3") +
  labs(
    title = "Korrelation zwischen Monat und zurückgelegter Distanz",
    x = "Jahr",
    y = "Korrelation",
    color = "Jahr"
  ) +
  theme_minimal()

# Korrelation zwischen Tageszeit und zurückgelegter Distanz für jedes Jahr
cor_period_by_year <- all_records %>%
  group_by(year, period) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop') %>%
  group_by(year) %>%
  summarize(correlation = cor(as.numeric(as.factor(period)), total_distance))

p4 <- ggplot(cor_period_by_year, aes(x = factor(year), y = correlation, color = factor(year), group = 1)) +
  geom_line(size = 1.5) +
  geom_point(size = 4) +
  scale_color_brewer(palette = "Set3") +
  labs(
    title = "Korrelation zwischen Tageszeit und zurückgelegter Distanz",
    x = "Jahr",
    y = "Korrelation",
    color = "Jahr"
  ) +
  theme_minimal()

# Trendanalyse der zurückgelegten Distanz über die Monate hinweg (2024) mit linearer Regression
trend_2024 <- records_2024 %>%
  group_by(month) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

p5 <- ggplot(trend_2024, aes(x = as.numeric(month), y = total_distance)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(
    title = "Trend der zurückgelegten Distanz über die Monate hinweg (2024)",
    x = "Monat",
    y = "Distanz (km)"
  ) +
  theme_minimal()

# Gesamt-Korrelation zwischen Monat und zurückgelegter Distanz (2022-2024)
cor_overall_month <- all_records %>%
  group_by(month) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop') %>%
  summarize(correlation = cor(as.numeric(month), total_distance))

p6 <- ggplot(cor_overall_month, aes(x = 1, y = correlation)) +
  geom_point(size = 4) +
  scale_x_continuous(breaks = NULL) +
  labs(
    title = "Gesamt-Korrelation zwischen Monat und zurückgelegter Distanz (2022-2024)",
    x = "",
    y = "Korrelation"
  ) +
  theme_minimal()

# Korrelation zwischen Art der Aktivität und zurückgelegter Distanz für jedes Jahr
cor_activity_by_year <- all_records %>%
  group_by(year, activity1) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop') %>%
  group_by(year) %>%
  summarize(correlation = cor(as.numeric(as.factor(activity1)), total_distance))

p7 <- ggplot(cor_activity_by_year, aes(x = factor(year), y = correlation, color = factor(year), group = 1)) +
  geom_line(size = 1.5) +
  geom_point(size = 4) +
  scale_color_brewer(palette = "Set3") +
  labs(
    title = "Korrelation zwischen Art der Aktivität und zurückgelegter Distanz",
    x = "Jahr",
    y = "Korrelation",
    color = "Jahr"
  ) +
  theme_minimal()

# Gesamt-Korrelation zwischen Art der Aktivität und zurückgelegter Distanz (2022-2024)
cor_overall_activity <- all_records %>%
  group_by(activity1) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop') %>%
  summarize(correlation = cor(as.numeric(as.factor(activity1)), total_distance))

p8 <- ggplot(cor_overall_activity, aes(x = 1, y = correlation)) +
  geom_point(size = 4) +
  scale_x_continuous(breaks = NULL) +
  labs(
    title = "Gesamt-Korrelation zwischen Art der Aktivität und zurückgelegter Distanz (2022-2024)",
    x = "",
    y = "Korrelation"
  ) +
  theme_minimal()

# Arrange plots in grid
grid.arrange(
  p1, p2, p3, p4, p5, p6, p7, p8,
  ncol = 2
)


```

#Auswertungen erweitert

```{r}
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(scales)
library(geosphere)
library(lubridate)
library(gridExtra)
library(GGally)
library(RColorBrewer)

# Hilfsfunktion zur Klassifizierung der Tageszeit
time_of_day <- function(hour) {
  case_when(
    hour >= 6 & hour < 10 ~ "Morgen (06-10 Uhr)",
    hour >= 10 & hour < 14 ~ "Mittag (10-14 Uhr)",
    hour >= 14 & hour < 18 ~ "Nachmittag (14-18 Uhr)",
    hour >= 18 & hour < 22 ~ "Abend (18-22 Uhr)",
    TRUE ~ "Nacht (22-06 Uhr)"
  )
}

process_year_data <- function(records_filtered, year_label) {
  # Filter records by timestamp for the specified year
  records_filtered <- records_filtered %>%
    filter(grepl(year_label, timestamp))
  
  # Parse the activity column
  records_filtered <- records_filtered %>%
    mutate(activity = gsub("list\\(list\\(type = c\\(|\\), confidence = c\\(|\\)\\)", "", activity)) %>%
    separate(activity, into = c("activity1", "activity2"), sep = ", confidence = ") %>%
    separate(activity1, into = c("activity1", "activity1_confidence"), sep = ", ") %>%
    separate(activity2, into = c("activity2", "activity2_confidence"), sep = ", ")
  
  # Convert lat/lon from E7 to decimal degrees
  records_filtered <- records_filtered %>%
    mutate(latitude = latitudeE7 / 1e7,
           longitude = longitudeE7 / 1e7)
  
  # Remove activities "Null" and "Still"
  records_filtered <- records_filtered %>%
    filter(!activity1 %in% c("Null", "Still"))
  
  # Remove rows with missing latitude or longitude
  records_filtered <- records_filtered %>%
    filter(!is.na(latitude) & !is.na(longitude))
  
  # Convert to spatial dataframe
  sf_records_filtered <- st_as_sf(records_filtered, coords = c("longitude", "latitude"), crs = 4326)
  
  # Calculate distances between consecutive points
  records_filtered <- records_filtered %>%
    arrange(timestamp) %>%
    mutate(
      dist = distHaversine(cbind(longitude, latitude), cbind(lag(longitude), lag(latitude))) / 1000, # Convert to km
      timestamp = as.POSIXct(timestamp, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC"),
      year = year(timestamp),
      month = month(timestamp, label = TRUE, abbr = FALSE), # Monate als Namen
      day = wday(timestamp, label = TRUE, abbr = FALSE), # Wochentage als Namen
      hour = hour(timestamp),
      period = time_of_day(hour)
    ) %>%
    replace_na(list(dist = 0))  # Replace NA distances with 0
  
  return(records_filtered)
}

# Assuming records_N is loaded
records_2022 <- process_year_data(records_N, "2022")
records_2023 <- process_year_data(records_N, "2023")
records_2024 <- process_year_data(records_N, "2024")

# Combine all years
all_records <- bind_rows(records_2022, records_2023, records_2024)

# Define the order of periods and days
all_records$period <- factor(all_records$period, levels = c("Morgen (06-10 Uhr)", "Mittag (10-14 Uhr)", "Nachmittag (14-18 Uhr)", "Abend (18-22 Uhr)", "Nacht (22-06 Uhr)"))
all_records$day <- factor(all_records$day, levels = c("Montag", "Dienstag", "Mittwoch", "Donnerstag", "Freitag", "Samstag", "Sonntag"))

# Analyse Verteilung, Korrelation und Trend

# Verteilung der zurückgelegten Distanz nach Tageszeit und Jahr
dist_by_period_year <- all_records %>%
  group_by(year, period) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

p1 <- ggplot(dist_by_period_year, aes(x = period, y = total_distance, fill = factor(year))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Verteilung der zurückgelegten Distanz nach Tageszeit und Jahr",
    x = "Tageszeit",
    y = "Distanz (km)",
    fill = "Jahr"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Verteilung der zurückgelegten Distanz nach Monat und Jahr
dist_by_month_year <- all_records %>%
  group_by(year, month) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

p2 <- ggplot(dist_by_month_year, aes(x = month, y = total_distance, fill = factor(year))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Verteilung der zurückgelegten Distanz nach Monat und Jahr",
    x = "Monat",
    y = "Distanz (km)",
    fill = "Jahr"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Korrelation zwischen Monat und zurückgelegter Distanz für jedes Jahr
cor_by_year <- all_records %>%
  group_by(year, month) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop') %>%
  group_by(year) %>%
  summarize(correlation = cor(as.numeric(month), total_distance))

p3 <- ggplot(cor_by_year, aes(x = factor(year), y = correlation, color = factor(year), group = 1)) +
  geom_line(size = 1.5) +
  geom_point(size = 4) +
  scale_color_brewer(palette = "Set3") +
  labs(
    title = "Korrelation zwischen Monat und zurückgelegter Distanz",
    x = "Jahr",
    y = "Korrelation",
    color = "Jahr"
  ) +
  theme_minimal()

# Korrelation zwischen Tageszeit und zurückgelegter Distanz für jedes Jahr
cor_period_by_year <- all_records %>%
  group_by(year, period) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop') %>%
  group_by(year) %>%
  summarize(correlation = cor(as.numeric(as.factor(period)), total_distance))

p4 <- ggplot(cor_period_by_year, aes(x = factor(year), y = correlation, color = factor(year), group = 1)) +
  geom_line(size = 1.5) +
  geom_point(size = 4) +
  scale_color_brewer(palette = "Set3") +
  labs(
    title = "Korrelation zwischen Tageszeit und zurückgelegter Distanz",
    x = "Jahr",
    y = "Korrelation",
    color = "Jahr"
  ) +
  theme_minimal()

# Trendanalyse der zurückgelegten Distanz über die Monate hinweg (2024) mit linearer Regression
trend_2024 <- records_2024 %>%
  group_by(month) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

p5 <- ggplot(trend_2024, aes(x = as.numeric(month), y = total_distance)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(
    title = "Trend der zurückgelegten Distanz über die Monate hinweg (2024)",
    x = "Monat",
    y = "Distanz (km)"
  ) +
  theme_minimal()

# Gesamt-Korrelation zwischen Monat und zurückgelegter Distanz (2022-2024)
cor_overall_month <- all_records %>%
  group_by(month) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop') %>%
  summarize(correlation = cor(as.numeric(month), total_distance))

p6 <- ggplot(cor_overall_month, aes(x = 1, y = correlation)) +
  geom_point(size = 4) +
  scale_x_continuous(breaks = NULL) +
  labs(
    title = "Gesamt-Korrelation zwischen Monat und zurückgelegter Distanz (2022-2024)",
    x = "",
    y = "Korrelation"
  ) +
  theme_minimal()

# Gesamt-Korrelation zwischen Art der Aktivität und zurückgelegter Distanz (2022-2024)
cor_overall_activity <- all_records %>%
  group_by(activity1) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop') %>%
  summarize(correlation = cor(as.numeric(as.factor(activity1)), total_distance))

p7 <- ggplot(cor_overall_activity, aes(x = 1, y = correlation)) +
  geom_point(size = 4) +
  scale_x_continuous(breaks = NULL) +
  labs(
    title = "Gesamt-Korrelation zwischen Art der Aktivität und zurückgelegter Distanz (2022-2024)",
    x = "",
    y = "Korrelation"
  ) +
  theme_minimal()

# Heatmap der Aktivität pro Stunde und Tag
activity_heatmap <- all_records %>%
  group_by(year, day, hour) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

p8 <- ggplot(activity_heatmap, aes(x = hour, y = day, fill = total_distance)) +
  geom_tile() +
  facet_wrap(~ year) +
  scale_fill_gradient(low = "white", high = "red") +
  labs(
    title = "Heatmap der Aktivität pro Stunde und Tag",
    x = "Stunde",
    y = "Tag",
    fill = "Distanz (km)"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(angle = 0, hjust = 1))

# Heatmap der Aktivität pro Monat
activity_heatmap_month <- all_records %>%
  group_by(year, month) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

p9 <- ggplot(activity_heatmap_month, aes(x = month, y = factor(year), fill = total_distance)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "red") +
  labs(
    title = "Heatmap der Aktivität pro Monat",
    x = "Monat",
    y = "Jahr",
    fill = "Distanz (km)"
  ) +
  theme_minimal()

# Vergleich der zurückgelegten Distanzen zwischen verschiedenen Aktivitäten
activity_comparison <- all_records %>%
  group_by(activity1) %>%
  summarize(total_distance = sum(dist, na.rm = TRUE), .groups = 'drop')

p10 <- ggplot(activity_comparison, aes(x = activity1, y = total_distance, fill = activity1)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Vergleich der zurückgelegten Distanzen zwischen verschiedenen Aktivitäten",
    x = "Aktivität",
    y = "Distanz (km)",
    fill = "Aktivität"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Arrange plots in grid
grid.arrange(
  p1, p2, p3, p4, p5, p6, p7, p8, p9, p10,
  ncol = 2
)

# Verteilung der zurückgelegten Distanz nach Tageszeit und Jahr:
# 
# Es zeigt sich, dass die zurückgelegte Distanz in den Jahren 2022, 2023 und 2024 zu verschiedenen Tageszeiten variiert.
# Im Jahr 2022 war die zurückgelegte Distanz am Nachmittag (14-18 Uhr) und am Abend (18-22 Uhr) am höchsten.
# Im Jahr 2023 war die Distanz am Nachmittag (14-18 Uhr) am höchsten, gefolgt vom Abend (18-22 Uhr).
# Im Jahr 2024 scheint der Trend ähnlich zu sein, mit den höchsten Distanzen am Nachmittag und Abend.
# Schlussfolgerung: Die Aktivitätsmuster scheinen über die Jahre hinweg relativ konsistent zu sein, mit einem Fokus auf Aktivitäten am Nachmittag und Abend.
# Verteilung der zurückgelegten Distanz nach Monat und Jahr:
# 
# Diese Grafik zeigt, wie die zurückgelegte Distanz in den einzelnen Monaten der Jahre 2022, 2023 und 2024 variiert.
# In allen Jahren gibt es Spitzen in den Sommermonaten (Juni, Juli, August) und niedrigere Distanzen in den Wintermonaten (Dezember, Januar, Februar).
# Schlussfolgerung: Es gibt saisonale Schwankungen in der zurückgelegten Distanz, wobei im Sommer mehr Aktivität zu verzeichnen ist.
# Korrelation zwischen Monat und zurückgelegter Distanz:
# 
# Die Korrelationen zwischen den Monaten und den zurückgelegten Distanzen zeigen, dass es in den Jahren 2022 und 2023 positive Korrelationen gibt, die jedoch schwach sind.
# Im Jahr 2024 ist die Korrelation etwas stärker positiv.
# Schlussfolgerung: Die monatliche Variation der Distanzen ist nicht stark ausgeprägt, zeigt jedoch einen leichten Trend zu höheren Distanzen in bestimmten Monaten.
# Korrelation zwischen Tageszeit und zurückgelegter Distanz:
# 
# Die Korrelationen zwischen den Tageszeiten und den zurückgelegten Distanzen sind in allen Jahren negativ, was bedeutet, dass es keinen klaren Zusammenhang zwischen der Tageszeit und der Distanz gibt.
# Schlussfolgerung: Die Tageszeit beeinflusst die zurückgelegte Distanz nicht signifikant.
# Trend der zurückgelegten Distanz über die Monate hinweg (2024):
# 
# Diese Grafik zeigt einen positiven Trend in der zurückgelegten Distanz über die Monate im Jahr 2024.
# Die lineare Regression zeigt eine Zunahme der Distanzen im Laufe des Jahres.
# Schlussfolgerung: Im Jahr 2024 nimmt die Aktivität im Laufe des Jahres zu.
# Gesamt-Korrelation zwischen Monat und zurückgelegter Distanz (2022-2024):
# 
# Die Gesamt-Korrelation zwischen Monat und zurückgelegter Distanz ist sehr niedrig.
# Schlussfolgerung: Es gibt keinen signifikanten Zusammenhang zwischen den Monaten und der zurückgelegten Distanz über die Jahre hinweg.
# Gesamt-Korrelation zwischen Art der Aktivität und zurückgelegter Distanz (2022-2024):
# 
# Diese Korrelation ist etwas höher, was darauf hinweist, dass bestimmte Aktivitäten mit höheren Distanzen verbunden sind.
# Schlussfolgerung: Die Art der Aktivität beeinflusst die zurückgelegte Distanz stärker als der Monat.
# Heatmap der Aktivität pro Stunde und Tag:
# 
# Diese Heatmap zeigt die Verteilung der zurückgelegten Distanzen über verschiedene Stunden und Tage der Woche in den Jahren 2022, 2023 und 2024.
# Es gibt eine höhere Aktivität an Wochentagen und in den späten Nachmittags- und Abendstunden.
# Schlussfolgerung: Die Aktivität ist an den Wochentagen konsistenter, während am Wochenende weniger Aktivität stattfindet.
# Heatmap der Aktivität pro Monat:
# 
# Diese Heatmap zeigt die monatliche Verteilung der zurückgelegten Distanzen in den Jahren 2022, 2023 und 2024.
# Die Aktivität ist im Sommer höher und im Winter niedriger.
# Schlussfolgerung: Die saisonale Variation der Aktivität ist in allen Jahren ähnlich, mit Spitzen im Sommer.
# Vergleich der zurückgelegten Distanzen zwischen verschiedenen Aktivitäten:
# 
# Diese Grafik zeigt die Unterschiede in der zurückgelegten Distanz zwischen verschiedenen Aktivitäten.
# Aktivitäten wie "IN_VEHICLE" und "ON_FOOT" haben höhere zurückgelegte Distanzen im Vergleich zu anderen Aktivitäten.
# Schlussfolgerung: Bestimmte Aktivitäten, insbesondere solche, die mit Bewegung verbunden sind, führen zu höheren zurückgelegten Distanzen.
# Gesamtbewertung:
# 
# Die Analysen zeigen konsistente Aktivitätsmuster über die Jahre hinweg, mit höheren Distanzen im Sommer und zu bestimmten Tageszeiten.
# Die Art der Aktivität beeinflusst die zurückgelegte Distanz stärker als die Tageszeit oder der Monat.
# Es gibt saisonale Schwankungen in der Aktivität, wobei der Sommer eine Spitzenzeit für zurückgelegte Distanzen ist.

```

# weitere Anaylsen

```{r}
# Lade notwendige Bibliotheken
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(scales)
library(geosphere)
library(lubridate)
library(gridExtra)
library(GGally)
library(RColorBrewer)
library(cluster)
library(factoextra)
library(viridis)
library(spdep)
library(dbscan)
library(igraph)
library(reshape2)
library(gganimate)
library(plotly)

# Hilfsfunktion zur Klassifizierung der Tageszeit
time_of_day <- function(hour) {
  case_when(
    hour >= 6 & hour < 10 ~ "Morgen (06-10 Uhr)",
    hour >= 10 & hour < 14 ~ "Mittag (10-14 Uhr)",
    hour >= 14 & hour < 18 ~ "Nachmittag (14-18 Uhr)",
    hour >= 18 & hour < 22 ~ "Abend (18-22 Uhr)",
    TRUE ~ "Nacht (22-06 Uhr)"
  )
}

# Funktion zur Verarbeitung von Daten eines bestimmten Jahres
process_year_data <- function(records_filtered, year_label) {
  # Filtere Datensätze nach dem angegebenen Jahr
  records_filtered <- records_filtered %>%
    filter(grepl(year_label, timestamp))
  
  # Analysiere die Aktivitätsspalte
  records_filtered <- records_filtered %>%
    mutate(activity = gsub("list\\(list\\(type = c\\(|\\), confidence = c\\(|\\)\\)", "", activity)) %>%
    separate(activity, into = c("activity1", "activity2"), sep = ", confidence = ", fill = "right", extra = "drop") %>%
    separate(activity1, into = c("activity1", "activity1_confidence"), sep = ", ", fill = "right") %>%
    separate(activity2, into = c("activity2", "activity2_confidence"), sep = ", ", fill = "right")
  
  # Konvertiere Latitude/Longitude von E7 in Dezimalgrade
  records_filtered <- records_filtered %>%
    mutate(latitude = latitudeE7 / 1e7,
           longitude = longitudeE7 / 1e7)
  
  # Entferne Aktivitäten "Null" und "Still"
  records_filtered <- records_filtered %>%
    filter(!activity1 %in% c("Null", "Still"))
  
  # Entferne Zeilen mit fehlender Latitude oder Longitude
  records_filtered <- records_filtered %>%
    filter(!is.na(latitude) & !is.na(longitude))
  
  # Weitere Bereinigung des Feldes activity1
  records_filtered <- records_filtered %>%
    mutate(activity1 = gsub("list\\(activity = \"|\"\\)", "", activity1)) %>%
    filter(activity1 != "NULL")
  
  # Berechne Distanzen zwischen aufeinanderfolgenden Punkten
  records_filtered <- records_filtered %>%
    arrange(timestamp) %>%
    mutate(
      dist = distHaversine(cbind(longitude, latitude), cbind(lag(longitude), lag(latitude))) / 1000, # Umrechnung in km
      timestamp = as.POSIXct(timestamp, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC"),
      year = year(timestamp),
      month = month(timestamp, label = TRUE, abbr = FALSE), # Monate als Namen
      day = wday(timestamp, label = TRUE, abbr = FALSE), # Wochentage als Namen
      hour = hour(timestamp),
      period = time_of_day(hour)
    ) %>%
    replace_na(list(dist = 0))  # Ersetze NA-Distanzen durch 0
  
  return(records_filtered)
}

# Angenommen, records_N ist geladen
records_2022 <- process_year_data(records_N, "2022")
records_2023 <- process_year_data(records_N, "2023")
records_2024 <- process_year_data(records_N, "2024")

# Kombiniere die Daten für alle Jahre
all_records <- bind_rows(records_2022, records_2023, records_2024)

# Definiere die Reihenfolge der Perioden und Tage
all_records$period <- factor(all_records$period, levels = c("Morgen (06-10 Uhr)", "Mittag (10-14 Uhr)", "Nachmittag (14-18 Uhr)", "Abend (18-22 Uhr)", "Nacht (22-06 Uhr)"))
all_records$day <- factor(all_records$day, levels = c("Montag", "Dienstag", "Mittwoch", "Donnerstag", "Freitag", "Samstag", "Sonntag"))

# Bereite Daten für das Clustering vor
clustering_data <- all_records %>%
  select(longitude, latitude, activity1) %>%
  mutate(activity1 = as.numeric(factor(activity1)))

# Führe k-means Clustering durch
set.seed(123)
kmeans_result <- kmeans(clustering_data[, c("longitude", "latitude")], centers = 5)

# Füge Clusterinformationen zu den Daten hinzu
all_records$cluster <- factor(kmeans_result$cluster)

# Clustering nach Jahr
clustering_data_year <- all_records %>%
  select(longitude, latitude, year)

set.seed(123)
kmeans_result_year <- kmeans(clustering_data_year[, c("longitude", "latitude")], centers = 5)

# Füge Jahres-Clusterinformationen zu den Daten hinzu
all_records$cluster_year <- factor(kmeans_result_year$cluster)

# Visualisiere tägliche Aktivitätsmuster
hourly_activity <- all_records %>%
  mutate(hour = hour(timestamp)) %>%
  group_by(hour, activity1) %>%
  summarize(count = n()) %>%
  ungroup()

p7 <- ggplot(hourly_activity, aes(x = hour, y = count, color = activity1)) +
  geom_line() +
  scale_x_continuous(breaks = 0:23) +
  labs(
    title = "Tägliche Aktivitätsmuster",
    x = "Stunde des Tages",
    y = "Aktivitätsanzahl",
    color = "Aktivität"
  ) +
  theme_minimal()

# Wöchentliche Muster
weekly_activity <- all_records %>%
  group_by(day, activity1) %>%
  summarize(count = n()) %>%
  ungroup()

p8 <- ggplot(weekly_activity, aes(x = day, y = count, fill = activity1)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Wöchentliche Aktivitätsmuster",
    x = "Wochentag",
    y = "Aktivitätsanzahl",
    fill = "Aktivität"
  ) +
  theme_minimal()

# Monatliche Muster
monthly_activity <- all_records %>%
  group_by(month, activity1) %>%
  summarize(count = n()) %>%
  ungroup()

p9 <- ggplot(monthly_activity, aes(x = month, y = count, fill = activity1)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Monatliche Aktivitätsmuster",
    x = "Monat",
    y = "Aktivitätsanzahl",
    fill = "Aktivität"
  ) +
  theme_minimal()

# Dichtekarten
sf_all_records <- st_as_sf(all_records, coords = c("longitude", "latitude"), crs = 4326)

# Korrelation Analyse
activity_period_corr <- all_records %>%
  select(activity1, period) %>%
  group_by(activity1, period) %>%
  summarize(count = n()) %>%
  spread(key = period, value = count, fill = 0)
cor_matrix <- cor(activity_period_corr[-1])

p15 <- ggplot(melt(cor_matrix), aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_viridis_c() +
  labs(
    title = "Korrelation Heatmap der Aktivitäten und Perioden",
    x = "Aktivität",
    y = "Periode"
  ) +
  theme_minimal()

# Jahr-für-Jahr Vergleich
yearly_activity <- all_records %>%
  group_by(year, activity1) %>%
  summarize(count = n()) %>%
  ungroup()

p17 <- ggplot(yearly_activity, aes(x = year, y = count, fill = activity1)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Jahr-für-Jahr Aktivitätsvergleich",
    x = "Jahr",
    y = "Aktivitätsanzahl",
    fill = "Aktivität"
  ) +
  theme_minimal()

# # Animierte Karten
# animated_map <- ggplot(all_records, aes(x = longitude, y = latitude, color = activity1)) +
#   geom_point(size = 2, alpha = 0.6) +
#   transition_time(timestamp) +
#   labs(
#     title = "Animierte Karte der Aktivitäten",
#     x = "Längengrad",
#     y = "Breitengrad",
#     color = "Aktivität"
#   ) +
#   theme_minimal()
# 
# animate(animated_map, renderer = gifski_renderer())

# 3D Visualisierungen
p19 <- plot_ly(all_records, x = ~longitude, y = ~latitude, z = ~elevation, color = ~activity1, type = "scatter3d", mode = "markers") %>%
  layout(title = "3D Visualisierung der Aktivitäten")

# Drucke jedes Diagramm einzeln
print(p7)
print(p8)
print(p9)
print(p15)
# plotly Ausgaben werden direkt in interaktiven Sitzungen gerendert
# p16 ist ein igraph Plot, der direkt in interaktiven Sitzungen gerendert wird
print(p17)

# Anordnung zusätzlicher Diagramme im Raster
grid.arrange(
  p7, p8, p9, p15, p17,
  ncol = 1
)

```

